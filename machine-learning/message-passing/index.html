



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.4.3">
    
    
      
        <title>Computational Representations of Message Passing - Essays on Data Science</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.30686662.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="#03a9f4">
      
    
    
      <script src="../../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="https://unpkg.com/mermaid@7.1.2/dist/mermaid.css">
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "UA-12498603-3", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="light-blue" data-md-color-accent="light-blue">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#computational-representations-of-message-passing" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../.." title="Essays on Data Science" class="md-header-nav__button md-logo">
          
            <i class="md-icon">library_books</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Essays on Data Science
            </span>
            <span class="md-header-nav__topic">
              
                Computational Representations of Message Passing
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/ericmjl/essays-on-data-science/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    ericmjl/essays-on-data-science
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../.." title="Essays on Data Science" class="md-nav__button md-logo">
      
        <i class="md-icon">library_books</i>
      
    </a>
    Essays on Data Science
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/ericmjl/essays-on-data-science/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    ericmjl/essays-on-data-science
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Essays on Data Science" class="md-nav__link">
      Essays on Data Science
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Computing
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Computing
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../computing/recursion/" title="Recursion" class="md-nav__link">
      Recursion
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked>
    
    <label class="md-nav__link" for="nav-3">
      Machine learning
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Machine learning
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../computational-bayesian-stats/" title="An Introduction to Probability and Computational Bayesian Statistics" class="md-nav__link">
      An Introduction to Probability and Computational Bayesian Statistics
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Computational Representations of Message Passing
      </label>
    
    <a href="./" title="Computational Representations of Message Passing" class="md-nav__link md-nav__link--active">
      Computational Representations of Message Passing
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction-to-message-passing" class="md-nav__link">
    Introduction to Message Passing
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#functions-on-nodes" class="md-nav__link">
    Functions on Nodes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#message-passing" class="md-nav__link">
    Message Passing
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computational-implementations-of-message-passing" class="md-nav__link">
    Computational Implementations of Message Passing
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#object-oriented-implementation" class="md-nav__link">
    Object-Oriented Implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-algebra-implementation" class="md-nav__link">
    Linear Algebra Implementation
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adjacency-variant-1-n-degree-adjacency-matrix" class="md-nav__link">
    Adjacency Variant 1: N-degree adjacency matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adjacency-variant-2-graph-laplacian-matrix" class="md-nav__link">
    Adjacency Variant 2: Graph laplacian matrix
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#message-passing-on-multiple-graphs" class="md-nav__link">
    Message Passing on Multiple Graphs
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementation-1-for-loops-over-pairs-of-adjacency-and-feature-matrices" class="md-nav__link">
    Implementation 1: For-loops over pairs of adjacency and feature matrices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-2-sparse-matrices" class="md-nav__link">
    Implementation 2: Sparse Matrices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-3-size-batched-matrix-multiplication" class="md-nav__link">
    Implementation 3: Size-batched matrix multiplication
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-4-batched-padded-matrix-multiplication" class="md-nav__link">
    Implementation 4: Batched padded matrix multiplication
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concluding-words" class="md-nav__link">
    Concluding Words
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#acknowledgments" class="md-nav__link">
    Acknowledgments
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#appendix" class="md-nav__link">
    Appendix
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#equivalence-between-padded-and-non-padded-message-passing" class="md-nav__link">
    Equivalence between padded and non-padded message passing
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../reimplementing-models/" title="Reimplementing and Testing Deep Learning Models" class="md-nav__link">
      Reimplementing and Testing Deep Learning Models
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Software skills
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        Software skills
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../software-skills/" title="Software Skills" class="md-nav__link">
      Software Skills
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../software-skills/code-formatting/" title="Formatting your code" class="md-nav__link">
      Formatting your code
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../software-skills/documentation/" title="Documenting your code" class="md-nav__link">
      Documenting your code
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../software-skills/refactoring/" title="Refactoring your code" class="md-nav__link">
      Refactoring your code
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../software-skills/testing/" title="Testing your code" class="md-nav__link">
      Testing your code
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Terminal
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Terminal
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../terminal/cli-tools/" title="Tools and Upgrades for your CLI" class="md-nav__link">
      Tools and Upgrades for your CLI
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../terminal/pre-commits/" title="Using `pre-commit` git hooks to automate code checks" class="md-nav__link">
      Using `pre-commit` git hooks to automate code checks
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      Workflow
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        Workflow
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../workflow/code-review/" title="Practicing Code Review" class="md-nav__link">
      Practicing Code Review
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../workflow/effective-commit-messages/" title="Effective Git Commits in Data Science" class="md-nav__link">
      Effective Git Commits in Data Science
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../workflow/gitflow/" title="Principled Git-based Workflow in Collaborative Data Science Projects" class="md-nav__link">
      Principled Git-based Workflow in Collaborative Data Science Projects
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction-to-message-passing" class="md-nav__link">
    Introduction to Message Passing
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#functions-on-nodes" class="md-nav__link">
    Functions on Nodes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#message-passing" class="md-nav__link">
    Message Passing
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computational-implementations-of-message-passing" class="md-nav__link">
    Computational Implementations of Message Passing
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#object-oriented-implementation" class="md-nav__link">
    Object-Oriented Implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-algebra-implementation" class="md-nav__link">
    Linear Algebra Implementation
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adjacency-variant-1-n-degree-adjacency-matrix" class="md-nav__link">
    Adjacency Variant 1: N-degree adjacency matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adjacency-variant-2-graph-laplacian-matrix" class="md-nav__link">
    Adjacency Variant 2: Graph laplacian matrix
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#message-passing-on-multiple-graphs" class="md-nav__link">
    Message Passing on Multiple Graphs
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementation-1-for-loops-over-pairs-of-adjacency-and-feature-matrices" class="md-nav__link">
    Implementation 1: For-loops over pairs of adjacency and feature matrices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-2-sparse-matrices" class="md-nav__link">
    Implementation 2: Sparse Matrices
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-3-size-batched-matrix-multiplication" class="md-nav__link">
    Implementation 3: Size-batched matrix multiplication
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-4-batched-padded-matrix-multiplication" class="md-nav__link">
    Implementation 4: Batched padded matrix multiplication
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#concluding-words" class="md-nav__link">
    Concluding Words
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#acknowledgments" class="md-nav__link">
    Acknowledgments
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#appendix" class="md-nav__link">
    Appendix
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#equivalence-between-padded-and-non-padded-message-passing" class="md-nav__link">
    Equivalence between padded and non-padded message passing
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/ericmjl/essays-on-data-science/edit/master/docs/machine-learning/message-passing.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="computational-representations-of-message-passing">Computational Representations of Message Passing</h1>
<p><strong>Abstract:</strong> Message passing on graphs,
also known as graph convolutions,
have become a popular research topic.
In this piece,
I aim to provide a short technical primer
on ways to implement message passing on graphs.
The goal is to provide clear pedagogy
on what message passing means mathematically,
and hopefully point towards cleaner computational implementations
of the key algorithmic pieces.</p>
<p><strong>Assumed knowledge:</strong>
We assume our reader has familiarity with elementary graph concepts.
More specifically, the terms “graph”, “nodes”, and “edges”
should be familiar terms.
Code examples in this technical piece will be written
using the Python programming language,
specifically using Python 3.7, NumPy 1.17 (in JAX), and NetworkX 2.2.</p>
<h2 id="introduction-to-message-passing">Introduction to Message Passing</h2>
<h3 id="functions-on-nodes">Functions on Nodes</h3>
<p>Message passing starts with a “function defined over nodes”,
which we will denote here as <span><span class="MathJax_Preview">f(v)</span><script type="math/tex">f(v)</script></span> (for “function of node/vertex v”).
What is this, one might ask?
In short,
this is nothing more than a numeric value of some kind
attached to every node in a graph.
This value could be scalar, vector, matrix, or tensor.</p>
<p>The semantic meaning of that value
is typically defined by the application domain
that the graph is being used in.
As a concrete example,
in molecules, a “function” defined over the molecular graph
could be the scalar-valued proton number.
Carbon would be represented by the function <span><span class="MathJax_Preview">f(v) = 6</span><script type="math/tex">f(v) = 6</script></span>.
Alternatively, it could be a vector of values
encompassing both the atomic mass and the number of valence electrons.
In this case, carbon would be represented by the function <span><span class="MathJax_Preview">f(v) = (6, 4)</span><script type="math/tex">f(v) = (6, 4)</script></span>.</p>
<p>Visually, one might represent it as follows:</p>
<!-- \<FIGURE\> -->

<p><img alt="" src="../message-passing-figures/figure-msg-passing-carbon-methane.png" /></p>
<h3 id="message-passing">Message Passing</h3>
<p>What then is message passing, or,
as the deep learning community has adopted, “graph convolution”?
At its core, message passing is nothing more
than a generic mathematical operation
defined between a node’s function value
and its neighbors function value.</p>
<p>As an example,
one may define a message passing operation
to be the summation the function evaluated at a node
with the function evaluated on its neighbor’s nodes.
Here is a simplistic example,
shown using a scalar on water:</p>
<p><img alt="" src="../message-passing-figures/figure-msg-passing-water.png" /></p>
<p>Summation is not the only message passing operation that can be defined.
In principle,
given any node (or vertex) <span><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span> and its neighbors <span><span class="MathJax_Preview">N(v)</span><script type="math/tex">N(v)</script></span> values,
we may write down a generic function <span><span class="MathJax_Preview">f(v, N(v))</span><script type="math/tex">f(v, N(v))</script></span>
that defines how the function value on each node
is to be shared with its neighbors.</p>
<h2 id="computational-implementations-of-message-passing">Computational Implementations of Message Passing</h2>
<p>For simplicity,
let us stay with the particular case
where the message passing operation is defined as
the summation of one’s neighbors values with one’s values.</p>
<h3 id="object-oriented-implementation">Object-Oriented Implementation</h3>
<p>With this definition in place,
we may then define a message passing operation in Python as follows:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">message_passing</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Object-oriented message passing operation.&quot;&quot;&quot;</span>

    <span class="n">G_new</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="n">new_value</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;value&quot;</span><span class="p">]</span>  <span class="c1"># assuming the value is stored under this key</span>
        <span class="n">neighbors</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">:</span>
            <span class="n">new_value</span> <span class="o">+=</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">neighbor</span><span class="p">][</span><span class="s2">&quot;value&quot;</span><span class="p">]</span>
        <span class="n">G_new</span><span class="o">.</span><span class="n">node</span><span class="p">[</span><span class="n">node</span><span class="p">][</span><span class="s2">&quot;value&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_value</span>
    <span class="k">return</span> <span class="n">G</span>
</pre></div>
</td></tr></table>

<p>Thinking about computational considerations,
we would naturally consider this implementation to be slow,
because it involves a for-loop over Python objects.
If we had multiple graphs
over which we wanted message passing to be performed,
the type-checking overhead in Python will naturally accumulate,
and may even dominate.</p>
<h3 id="linear-algebra-implementation">Linear Algebra Implementation</h3>
<p>How might we speed things up? As it turns out, linear algebra may be useful.</p>
<p>We know that every graph may be represented as an adjacency matrix <code>A</code>,
whose shape is <code>(n_nodes, n_nodes)</code>.
As long as we maintain proper node ordering,
we may also define a compatibly-shaped matrix <code>F</code> for node function values,
whose shape is <code>(n_nodes, n_features)</code>.</p>
<p>Taking advantage of this,
in order define the “self plus neighbors” message passing operation
in terms of linear algebra operations,
we may then modify <code>A</code> by adding to it a diagonal matrix of ones.
(In graph terminology,
this is equivalent to adding a self-loop to the adjacency matrix.)</p>
<p>Then, message passing,
as defined above,
is trivially the dot product of <code>A</code> and <code>F</code>:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">message_passing</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">F</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Message passing done by linear algebra.</span>

<span class="sd">    :param A: Adjacency-like matrix, whose shape is (n_nodes, n_nodes).</span>
<span class="sd">    :param F: Feature matrix, whose shape is (n_nodes, n_features).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">F</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>In principle, variants on the adjacency matrix are possible.
The only hard requirement for the matrix <code>A</code>
is that it has the shape <code>(n_nodes, n_nodes)</code>.</p>
<h4 id="adjacency-variant-1-n-degree-adjacency-matrix">Adjacency Variant 1: N-degree adjacency matrix</h4>
<p>The adjacency matrix represents connectivity by degree 1.
If we take the second matrix power of the adjacency matrix,
we get back the connectivity of nodes
at two degrees of separation away.
More generically:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">n_degree_adjacency</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the n-degree of separation adjacency matrix.</span>

<span class="sd">    :param A: Adjacency matrix, of shape (n_nodes, n_nodes)</span>
<span class="sd">    :param n: Number of degrees of separation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_power</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>Performing message passing using the N-degree adjacency matrix
effectively describes sharing of information
between nodes that are N-degrees of separation apart,
skipping intermediate neighbors.</p>
<h4 id="adjacency-variant-2-graph-laplacian-matrix">Adjacency Variant 2: Graph laplacian matrix</h4>
<p>The graph laplacian matrix is defined as
the diagonal degree matrix <code>D</code>
(where the diagonal entries are the degree of each node)
minus the adjacency matrix <code>A</code>: <code>L = D - A</code>.</p>
<p>This matrix is the discrete analog to the Laplacian operator,
and can give us information
about the discrete gradient between a node and its neighbors.</p>
<h2 id="message-passing-on-multiple-graphs">Message Passing on Multiple Graphs</h2>
<p>Thus far,
we have seen an efficient implementation
of message passing on a single graph
using linear algebra.</p>
<p>How would one perform message passing on multiple graphs, though?</p>
<p>This is a question
that has applications in graph neural networks
(especially in cheminformatics).
For the learning task where one has a batch of graphs,
and the supervised learning task is
to predict a scalar (or vector) value per graph,
knowing how to efficiently message pass over multiple graphs
is crucial to developing a performant graph neural network model.</p>
<p>The challenge here, though,
is that graphs generally are of variable size,
hence it is not immediately obvious how to “tensorify” the operations.</p>
<p>Let us look at a few alternatives,
starting with the most obvious (but also most inefficient),
building towards more efficient solutions.</p>
<h3 id="implementation-1-for-loops-over-pairs-of-adjacency-and-feature-matrices">Implementation 1: For-loops over pairs of adjacency and feature matrices</h3>
<p>If we multiple graphs,
they may be represented as a list of feature matrices
and a list of adjacency matrices.
The message passing operation, then,
may be defined by writing a for-loop over pairs of these matrices.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">message_passing</span><span class="p">(</span><span class="n">As</span><span class="p">,</span> <span class="n">Fs</span><span class="p">):</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">A</span><span class="p">,</span> <span class="n">F</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">As</span><span class="p">,</span> <span class="n">Fs</span><span class="p">):</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">F</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">outputs</span>
</pre></div>
</td></tr></table>

<p>Because of the for-loop,
the obvious downside here
is the overhead induced by running a for-loop over pairs of As and Fs.</p>
<h3 id="implementation-2-sparse-matrices">Implementation 2: Sparse Matrices</h3>
<p>Sparse matrices are an attractive alternative.
Instead of treating graphs as independent samples,
we may treat them as a single large graph on which we perform message passing.
If we order the nodes in our adjacency matrix and feature matrix correctly,
we will end up with a block diagonal adjacency matrix,
and vertically stacked feature matrices.</p>
<p><img alt="" src="../message-passing-figures/figure-message-passing-sparse.png" /></p>
<p>If we prepare the multiple graphs as a large disconnected graph,
then we will have a dense feature matrix of shape <code>(sum(n_nodes), n_feats)</code>,
and a sparse adjacency matrix of shape <code>(sum(n_nodes), sum(n_nodes))</code>.
Message passing then becomes a sparse-dense dot product:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">message_passing</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">F</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sparse</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">F</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>The upside here is that
message passing has been returned back to its natural form (a dot product).
The downsides here are that the data must be prepared as a single large graph,
hence we effectively lose
what one would call the “sample” (or “batch”) dimension.
Additionally, the most widely used deep learning libraries
do not support automatic differentiation
on sparse-dense or dense-sparse dot products,
hence limiting the use of this implementation in deep learning.</p>
<h3 id="implementation-3-size-batched-matrix-multiplication">Implementation 3: Size-batched matrix multiplication</h3>
<p>An alternative way to conceptualize message passing
is to think of graphs of the same size as belonging to a “size batch”.
We may then vertically stack the feature and adjacency matrices
of graphs of the same size together,
and perform a batched matrix multiplication,
ensuring that we preserve the sample/batch dimension in the final result.</p>
<p><img alt="" src="../message-passing-figures/figure-message-passing-graph-size.png" /></p>
<p>In terms of Python code, this requires special preparation of the graphs.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">jax.lax</span> <span class="kn">import</span> <span class="n">batch_matmul</span>

<span class="k">def</span> <span class="nf">feature_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
    <span class="c1"># ...</span>
    <span class="k">return</span> <span class="n">F</span>

<span class="k">def</span> <span class="nf">prep_data</span><span class="p">(</span><span class="n">Gs</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
    <span class="n">adjacency_matrices</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">feature_matrices</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">G</span> <span class="ow">in</span> <span class="n">Gs</span><span class="p">:</span>
        <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
        <span class="n">F</span> <span class="o">=</span> <span class="n">feature_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
        <span class="n">adjacency_matrices</span><span class="p">[</span><span class="n">size</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
        <span class="n">feature_matrices</span><span class="p">[</span><span class="n">size</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">size</span><span class="p">,</span> <span class="n">As</span> <span class="ow">in</span> <span class="n">adjacency_matrices</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">adjacency_matrices</span><span class="p">[</span><span class="n">size</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">As</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">size</span><span class="p">,</span> <span class="n">Fs</span> <span class="ow">in</span> <span class="n">feature_matrices</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">feature_matrices</span><span class="p">[</span><span class="n">size</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">Fs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">adjacency_matrices</span><span class="p">,</span> <span class="n">feature_matrices</span>

<span class="k">def</span> <span class="nf">message_passing</span><span class="p">(</span><span class="n">As</span><span class="p">,</span> <span class="n">Fs</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">As</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">F</span> <span class="o">=</span> <span class="n">Fs</span><span class="p">[</span><span class="n">size</span><span class="p">]</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">As</span><span class="p">[</span><span class="n">size</span><span class="p">]</span>

        <span class="n">result</span><span class="p">[</span><span class="n">size</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">F</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>
</td></tr></table>

<p>In this implementation,
we use <code>jax.lax.batch_matmul</code>,
which inherently assumes
that the first dimension is the sample/batch dimension,
and that the matrix multiplication happens on the subsequent dimensions.</p>
<p>An advantage here is that the number of loop overhead calls in Python
is reduced to the number of unique graph sizes that are present in the graph.
The disadvantage, though,
is that we have a dictionary data structure that we have to deal with,
which makes data handling in Python less natural
when dealing with linear algebra libraries.</p>
<h3 id="implementation-4-batched-padded-matrix-multiplication">Implementation 4: Batched padded matrix multiplication</h3>
<p>In this implementation,
we prepare the data in a different way.
Firstly, we must know the size of the largest graph ahead-of-time.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">size</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># largest graph size</span>
</pre></div>
</td></tr></table>

<p>We then pad every graph’s feature matrix with zeros along the node axis
until the node axis is as long as the largest graph size.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">prep_feats</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="c1"># F is of shape (n_nodes, n_feats)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
        <span class="n">F</span><span class="p">,</span>
        <span class="p">[</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span> <span class="o">-</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="p">],</span>
    <span class="p">)</span>
</pre></div>
</td></tr></table>

<p>We do the same with every adjacency matrix.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">prep_adjs</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="c1"># A is of shape (n_nodes, n_nodes)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
        <span class="n">A</span><span class="p">,</span>
        <span class="p">[</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">-</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">-</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
        <span class="p">],</span>
    <span class="p">)</span>
</pre></div>
</td></tr></table>

<p>Finally, we simply stack them into the data matrix:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">As</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">prep_adjs</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span> <span class="k">for</span> <span class="n">A</span> <span class="ow">in</span> <span class="n">As</span><span class="p">]</span>
<span class="n">Fs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">prep_feats</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span> <span class="k">for</span> <span class="n">F</span> <span class="ow">in</span> <span class="n">Fs</span><span class="p">]</span>
</pre></div>
</td></tr></table>

<p>Now, the shapes of our matrices are as follows:</p>
<ul>
<li><code>F</code> takes on the shape <code>(n_graphs, n_nodes, n_feats)</code></li>
<li><code>A</code> takes on the shape <code>(n_graphs, n_nodes, n_nodes)</code></li>
</ul>
<p>If we desire to be semantically consistent with our shapes,
then we might, by convention,
assign the first dimension to be the sample/batch dimension.</p>
<p>Finally, message passing is now trivially defined as a batch matrix multiply:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">message_passing</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">F</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">batch_matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">F</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>Visually, this is represented as follows:</p>
<p><img alt="" src="../message-passing-figures/figure-message-passing-batched.png" /></p>
<p>To this author’s best knowledge,
this should be the most efficient implementation of batched message passing
across multiple graphs
that also supports automatic differentiation,
while also maintaining parity with the written equation form,
hence preserving readability.
The problems associated with a for-loop,
sparse matrix multiplication,
and dictionary carries,
are removed.
Moreover, the sample/batch dimension is preserved,
hence it is semantically easy to map each graph
to its corresponding output value.
Given the current state of automatic differentiation libraries,
no additional machinery is necessary to support sparse matrix products.</p>
<p>The only disadvantage that this author can think of
is that zero-padding may not be intuitive at first glance,
and that the data must still be specially prepared and stacked first.</p>
<h2 id="concluding-words">Concluding Words</h2>
<p>This essay was initially motivated
by the myriad of difficult-to-read message passing implementations
present in the deep learning literature.
Frequently,
a for-loop of some kind is invoked,
or an undocumented list data structure is created,
in order to accomplish the message passing operation.
Moreover, the model implementation
is frequently not separated from the data preparation step,
which makes for convoluted
and mutually incompatible implementations
of message passing in neural networks.</p>
<p>It is my hope that while the research field is still in vogue,
a technical piece that advises researchers
on easily-readable and efficient implementations
of message passing on graphs
may help advance research practice.
In particular,
if our code can more closely match the equations listed in papers,
that will help facilitate
communication and verification of model implementations.</p>
<p>To help researchers get started,
an example implementation for the full data preparation
and batched padded matrix multiplies in JAX
is available on GitHub,
archived on Zenodo.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>I thank Rif. A. Saurous
for our discussion at the PyMC4 developer summit in Montreal, QC,
where his laser-like focus on “tensorify everything”
inspired many new thoughts in my mind.</p>
<p>Many thanks to my wife, Nan Li,
who first pointed me to the linear algebra equivalents of graphs.</p>
<p>I also thank David Duvenaud and Matthew J. Johnson
for their pedagogy while they were at Harvard.</p>
<h2 id="appendix">Appendix</h2>
<h3 id="equivalence-between-padded-and-non-padded-message-passing">Equivalence between padded and non-padded message passing</h3>
<p>To readers who may need an example to be convinced
that matrix multiplying the padded matrices
is equivalent to matrix multiplying the originals,
we show the Python example below.</p>
<p>Firstly, without padding:</p>
<div class="codehilite"><pre><span></span><span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">F</span><span class="p">)</span>

<span class="c1"># Value of M</span>
<span class="c1"># DeviceArray([[1, 0],</span>
            <span class="c1">#  [1, 1]], dtype=int32)</span>
</pre></div>

<p>And now, with padding:</p>
<div class="codehilite"><pre><span></span><span class="n">pad_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">F_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
    <span class="n">F</span><span class="p">,</span>
    <span class="n">pad_width</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_size</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">A_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
    <span class="n">A</span><span class="p">,</span>
    <span class="n">pad_width</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_size</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_size</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># F_pad:</span>
<span class="c1"># DeviceArray([[1, 0],</span>
<span class="c1">#              [1, 1],</span>
<span class="c1">#              [0, 0],</span>
<span class="c1">#              [0, 0]], dtype=int32)</span>

<span class="c1"># A_pad:</span>
<span class="c1"># DeviceArray([[1, 0, 0, 0],</span>
<span class="c1">#              [0, 1, 0, 0],</span>
<span class="c1">#              [0, 0, 0, 0],</span>
<span class="c1">#              [0, 0, 0, 0]], dtype=int32)</span>

<span class="n">M_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A_pad</span><span class="p">,</span> <span class="n">F_pad</span><span class="p">)</span>
<span class="c1"># M_pad:</span>
<span class="c1"># DeviceArray([[1, 0],</span>
<span class="c1">#              [1, 1],</span>
<span class="c1">#              [0, 0],</span>
<span class="c1">#              [0, 0]], dtype=int32)</span>
</pre></div>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../computational-bayesian-stats/" title="An Introduction to Probability and Computational Bayesian Statistics" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                An Introduction to Probability and Computational Bayesian Statistics
              </span>
            </div>
          </a>
        
        
          <a href="../reimplementing-models/" title="Reimplementing and Testing Deep Learning Models" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Reimplementing and Testing Deep Learning Models
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../../assets/fonts/font-awesome.css">
    
      <a href="http://www.shortwhale.com/ericmjl" class="md-footer-social__link fa fa-envelope"></a>
    
      <a href="https://github.com/ericmjl" class="md-footer-social__link fa fa-github"></a>
    
      <a href="https://twitter.com/ericmjl" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://linkedin.com/in/ericmjl" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.ac79c3b0.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
        <script src="https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js"></script>
      
    
  </body>
</html>